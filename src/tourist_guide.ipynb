{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6c3afb",
   "metadata": {},
   "source": [
    "## Dependencies installation\n",
    "\n",
    "We install the main dependencies that will be used alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d38c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27458f64",
   "metadata": {},
   "source": [
    "## Load the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8571e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# cargamos las variables/claves desde el .env\n",
    "dotenv_loaded = load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google API Key was not set properly, please share it here: \")\n",
    "    \n",
    "# comprobamos que se han cargado correctamente\n",
    "if os.environ[\"GOOGLE_API_KEY\"]==\"\":\n",
    "    print(\"'GOOGLE_API_KEY' wasn't set correctly. Please make sure the keys/variables are accesible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b3e98",
   "metadata": {},
   "source": [
    "Let's make a little trial to ensure the API key is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b736c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El máximo goleador vasco de LaLiga en la temporada 2020-2021 fue **Mikel Oyarzabal**, de la Real Sociedad, con **11 goles**.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Dime quien es el máximo goleador vasco de LaLiga en la temporada 2020-2021\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a832ec",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ef5c6",
   "metadata": {},
   "source": [
    "We will load the cities data so we can work on it and later divide it in chunks so it's more manageable. First we will code a function to help us divide each of the documents in pages before applying the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8becab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "def document_reader(path, doc_name):\n",
    "    \n",
    "    # Abrimos el archivo para leerlo de forma binaria\n",
    "    doc_path = path + doc_name\n",
    "    pdf_reader = PdfReader(doc_path)\n",
    "    \n",
    "    global_text = []\n",
    "    for i, page in enumerate(pdf_reader.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        # global_text[pdf_reader.pages[i].extract_text()] = {f\"Page {i+1}\": f\"{doc_name}\"}\n",
    "        \n",
    "        global_text.append({\n",
    "            \"page_content\": text.strip(), # limpia espacios sobrentes y los saltos de linea\n",
    "            \"doc_ubication\": { \"document\": doc_name, \"page\": i }\n",
    "        })\n",
    "        \n",
    "    return global_text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c549d",
   "metadata": {},
   "source": [
    "Now, by using function above we will create a list mixing everything in an only list so we have all the chunks/pages together and can operate easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7776d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 {'document': 'BARCELONA.pdf', 'page': 1}\n",
      "{'document': 'VALENCIA.pdf', 'page': 16}\n"
     ]
    }
   ],
   "source": [
    "def load_pdfs(data_dir=\"../data/\"):\n",
    "    documents = []\n",
    "    for file in os.listdir(\"../data/\"): # recorremos la lista de archivos en el directorio y aplicamos document_reader a cada uno de ellos\n",
    "        docs = document_reader(data_dir, file)\n",
    "        documents.extend(docs)\n",
    "    return documents\n",
    "\n",
    "documents = load_pdfs(\"../data/\")\n",
    "print(len(documents), documents[0][\"doc_ubication\"])\n",
    "print(documents[-1][\"doc_ubication\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab4dd9",
   "metadata": {},
   "source": [
    "Now we will split up everything on chunks. Each document will be having around of 40.000 characters what is a extremely large quantity if we take the whole sum of characters for every document on the data folder. Furthermore, it is not very convenient for adding them to the context window of some models, it may be difficult for these models to find the information in excessively long inputs (not to mention the increased cost of each request to the model...). \n",
    "\n",
    "That's why we will use `RecursiveCharacterTextSplitter` to divide the format following a recursive strategy in the chunk_size we decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d71136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total splits: 223\n",
      "First split content:\n",
      "page_content='www.spain.infoBarcelona' metadata={'document': 'BARCELONA.pdf', 'page': 1, 'start_index': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    # separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "docs = [Document(page_content=d[\"page_content\"], metadata=d[\"doc_ubication\"]) for d in documents]\n",
    "\n",
    "docs_splitted = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Total splits: {len(docs_splitted)}\")\n",
    "\n",
    "# Mostramos el primer split.\n",
    "print(f\"First split content:\\n{docs_splitted[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8685f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second split content:\n",
      "2\n",
      " Introducción 3\n",
      "Vive Barcelona: principales zonas  4\n",
      "  El Born \n",
      "  Gràcia y L´Eixample \n",
      "  Barrio Gótico \n",
      "  El Raval \n",
      "  Montjuïc \n",
      "  Plaça de Espanya \n",
      "  La Rambla \n",
      "  Basílica de la Sagrada Familia \n",
      "  Les Corts y Pedralbes \n",
      "Cultura  8\n",
      "  Museos \n",
      "  Centros de exposiciones \n",
      "Saborea Barcelona  10\n",
      "Barcelona en cada estación 12\n",
      "  Verano \n",
      "  Otoño \n",
      "  Invierno \n",
      "  Primavera \n",
      "Playas 14\n",
      "Cinco planes para disfrutar  15 \n",
      "en familia\n",
      "  PortAventura World \n",
      "  Parque de Atracciones Tibidabo \n",
      "  L ’Aquàrium \n",
      "  Zoo de Barcelona \n",
      "  Museu de la Música  \n",
      "  Las Golondrinas La ciudad escondida 16\n",
      "  Parques y jardines  \n",
      "  Museos secretos \n",
      "  Monumentos  \n",
      "  Los tejados de Barcelona \n",
      "Vivir la noche en Barcelona  19\n",
      "Rutas y paseos por la ciudad 20\n",
      "  Ruta romana \n",
      "  Ruta medieval \n",
      "  Ruta modernista \n",
      "  Ruta Gaudí \n",
      "  Ruta Miró \n",
      "  Ruta Picasso \n",
      "¿Qué visitar cerca de Barcelona? 23\n",
      "  Ciudades y lugares de interés \n",
      "  Naturaleza \n",
      "¿Cómo llegar? 25\n",
      "  AVE \n",
      "  Aeropuerto \n",
      "  Coche \n",
      "  Moverte por Barcelona\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Second split content:\\n{docs_splitted[1].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac64f46",
   "metadata": {},
   "source": [
    "Now that we have all the chunks, it's time to apply the embedding to them and to save them inside a vector store. This is useful for searching similarities between vectors and to determine wich of them are the most relevant to the question asked. We will use a vector store defined in memory and to generate the embeddings we will be using google embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5daa27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7312b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['370b4d1e-559b-4524-8e50-4d237f7534bd', 'ca83d60f-10c9-4f52-8843-81426b09d40c', '733086af-70cc-43ed-b250-bebb3d620466']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "document_ids = vector_store.add_documents(documents=docs_splitted)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10375a87",
   "metadata": {},
   "source": [
    "## Retrieval and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde030b8",
   "metadata": {},
   "source": [
    "With the embeddings already obtained and saved in the vector store now we will develop the model that will bring the more relevant parts of the text and give it to the LLM in order to give a supported answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce82109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(\n",
    "    \"You are a precise tourist guide. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. Always cite sources as as provided in the context. \\n\" +\n",
    "    \"Question: {question}\\n\" +\n",
    "    \"Context: {context}\\n\" +\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "tourist_guide_llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00c4f438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context:\n",
      "[Document(id='3d04e712-d8d1-4920-903b-597fb6946210', metadata={'document': 'BILBAO.pdf', 'page': 1, 'start_index': 0}, page_content='www.spain.infoBilbao'), Document(id='e7a4c4d3-6341-46fe-b092-6b5f8033af90', metadata={'document': 'BARCELONA.pdf', 'page': 1, 'start_index': 0}, page_content='www.spain.infoBarcelona'), Document(id='e5e120a3-7a19-44a2-be09-ffe4ad332ae3', metadata={'document': 'TENERIFE.pdf', 'page': 2, 'start_index': 0}, page_content='o Auditorio  de Tenerife  [vídeo  - ubicación ] \\n \\n \\no Plaza  de España [ vídeo  - ubicación ]'), Document(id='f23cd4fc-bbc5-4af3-aa4b-ad3c1ca107d5', metadata={'document': 'BILBAO.pdf', 'page': 8, 'start_index': 814}, page_content='quiat... T ambién hay espacio para escul -\\nturas de artistas vascos como Eduardo \\nChillida y Jorge Oteiza. \\n L www.guggenheim-bilbao.eus\\nSi buscas una pinacoteca más clásica, \\nla colección del Museo de Bellas Artes \\nes una de las más importantes de toda \\nEspaña. Viaja en el tiempo a través de \\npiezas que cubren diversas manifesta -\\nciones artísticas, desde el siglo XIII hasta \\nnuestros días. Más de 10 000 objetos, \\nentre los que se encuentran obras maes -\\ntras de El Greco, Goya, Zuloaga, Francis \\nBacon, Miquel Barceló o Antoni T àpies.\\n L www.bilbaomuseoa.eusCULTURA\\nUn museo de arte contemporáneo que \\nparece salido de una película de cien -\\ncia ficción, preciosas galerías con obras \\nmaestras de la pintura y la escultura, es -\\npectaculares escenarios para concier -\\ntos y obras de teatro… la agenda cultu -\\nral de Bilbao es inagotable.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"que puedo ver en Bilbao?\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question, k=4)\n",
    "# docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "print(f\"Retrieved context:\\n{retrieved_docs}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23c621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_citations(docs):\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\", \"unknown\").split(\"/\")[-1]\n",
    "        page = d.metadata.get(\"page\", \"NA\")\n",
    "        parts.append(f\"{d.page_content}\\n[Source: {src} Page: {page}]\")\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "913d9dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input for the LLM:\n",
      "You are a precise tourist guide. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. Always cite sources as as provided in the context. \n",
      "Question: que puedo ver en Bilbao?\n",
      "Context: www.spain.infoBilbao\n",
      "[Source: unknown Page: 1]\n",
      "\n",
      "---\n",
      "\n",
      "www.spain.infoBarcelona\n",
      "[Source: unknown Page: 1]\n",
      "\n",
      "---\n",
      "\n",
      "o Auditorio  de Tenerife  [vídeo  - ubicación ] \n",
      " \n",
      " \n",
      "o Plaza  de España [ vídeo  - ubicación ]\n",
      "[Source: unknown Page: 2]\n",
      "\n",
      "---\n",
      "\n",
      "quiat... T ambién hay espacio para escul -\n",
      "turas de artistas vascos como Eduardo \n",
      "Chillida y Jorge Oteiza. \n",
      " L www.guggenheim-bilbao.eus\n",
      "Si buscas una pinacoteca más clásica, \n",
      "la colección del Museo de Bellas Artes \n",
      "es una de las más importantes de toda \n",
      "España. Viaja en el tiempo a través de \n",
      "piezas que cubren diversas manifesta -\n",
      "ciones artísticas, desde el siglo XIII hasta \n",
      "nuestros días. Más de 10 000 objetos, \n",
      "entre los que se encuentran obras maes -\n",
      "tras de El Greco, Goya, Zuloaga, Francis \n",
      "Bacon, Miquel Barceló o Antoni T àpies.\n",
      " L www.bilbaomuseoa.eusCULTURA\n",
      "Un museo de arte contemporáneo que \n",
      "parece salido de una película de cien -\n",
      "cia ficción, preciosas galerías con obras \n",
      "maestras de la pintura y la escultura, es -\n",
      "pectaculares escenarios para concier -\n",
      "tos y obras de teatro… la agenda cultu -\n",
      "ral de Bilbao es inagotable.\n",
      "[Source: unknown Page: 8]\n",
      "Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = format_docs_with_citations(retrieved_docs)\n",
    "input = rag_prompt.invoke({\"question\": question, \"context\": context})\n",
    "print(f\"Input for the LLM:\\n{input.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c2e61ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM answer:\n",
      "In Bilbao, you can visit the Guggenheim Museum, which features contemporary art, and the Museo de Bellas Artes, which houses a collection of classical art (www.guggenheim-bilbao.eus, www.bilbaomuseoa.eus). The Museo de Bellas Artes contains over 10,000 objects from the 13th century to the present day [Source: unknown Page: 8].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = tourist_guide_llm.invoke(input)\n",
    "print(f\"LLM answer:\\n{answer.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe476672",
   "metadata": {},
   "source": [
    "## App Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81944561",
   "metadata": {},
   "source": [
    "Now after trying each step separatedly we can build the chat by combining the retrieval part with the LLM use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b703f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a day trip in northern Tenerife, I suggest visiting Puerto de la Cruz, where you can walk from the pier to Playa Martiánez, passing Plaza de Europa and Lago de Martiánez (Source: unknown Page: 11). You can also explore the Auditorio de Tenerife and Plaza de España (Source: unknown Page: 2). Remember to be cautious of the strong currents if you visit Playa del Ancón (Source: unknown Page: 11).\n"
     ]
    }
   ],
   "source": [
    "def ask_tguide(question: str, prompt, vector_store):\n",
    "    \n",
    "    retrieved_docs = vector_store.similarity_search(question, k=4)\n",
    "    context = format_docs_with_citations(retrieved_docs)\n",
    "    input = prompt.invoke({\"question\": question, \"context\": context})\n",
    "    return tourist_guide_llm.invoke(input).content\n",
    "\n",
    "\n",
    "print(ask_tguide(\"¿Me propones un itinerario de 1 día por Tenerife norte?\", rag_prompt, vector_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "from typing import Literal\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import START, StateGraph\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"][\"query\"]\n",
    "    \n",
    "    # usamos similarity search + rearnking con cross encoder porque está demostrado que para mayor precisión usar este es optimo\n",
    "    base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 30})\n",
    "    cross_encoder = HuggingFaceCrossEncoder(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    reranker = CrossEncoderReranker(model=cross_encoder, top_n=4)\n",
    "    retriever = ContextualCompressionRetriever(base_retriever=base_retriever, base_compressor=reranker)\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    # retrieved_docs = vector_store.similarity_search(query[\"query\"], k=4)\n",
    "    \n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
